'''
Toolbox for evaluating the trained model.
'''

import keras
import numpy as np
from numpy import newaxis
from collections import Counter

# Tensorflow
import tensorflow as tf
from tensorflow.python.keras import models
from tensorflow.python.keras import layers
from tensorflow.python.keras import regularizers

# Preprocessing
from featureExtractTool import *


'''
Classify a single pattern (an image of Mel-spectrogram)

Return two possibilties:
First is the probability of this pattern belonging to label 0
Second is the probability of this pattern belonging to label 1
'''
def classify_pattern(a_Model, a_Pattern):

    t_PtPredFracArr = a_Model.predict(a_Pattern)

    return t_PtPredFracArr[0]


'''
Classify a single song by using the majority voting of the
prediction results of its all windows.

Return a dictionary recording which class this song belongs to
and all the results of windows prediction.
'''
def classify_song(a_Model, a_Patterns, a_Label):

    # Init dict to store results
    t_Dict = {"#Songs" : 1, "#CorrectSongPred" : 0, "#Patterns" : 0, "#CorrectPatternPred" : 0}

    # Record number of patterns
    t_Dict["#Patterns"] = a_Patterns.shape[0]

    # Classify each pattern in this song
    for i in range(a_Patterns.shape[0]):

        # resize 2d pattern into 3D
        t_Pt = a_Patterns[i,:,:,:]
        t_PtPredFrac = classify_pattern(a_Model, t_Pt[newaxis,:,:,:])

        # Round predicted result to 1 or 0
        t_PtPred = int(round(t_PtPredFrac[a_Label]))

        # Record correct prediction
        if(t_PtPred == 1):
            t_Dict["#CorrectPatternPred"] += 1

    # Majority voting
    if(t_Dict["#CorrectPatternPred"] > t_Dict["#Patterns"]/2):
        t_Dict["#CorrectSongPred"] = 1

    return t_Dict


'''
Evaluate model by testing all songs in validation folder.
(Extracting the mel-spectrogram on the fly)
'''
def test_model(a_Model, a_Scalers, a_PathToSongDir, a_Label, a_SizeOfWindow, a_NumOfOverlapSample):

    # Init recorder of classification results
    t_AllResultsDict={}

    # Get name of each song and save as list
    t_AllFiles = os.listdir(a_PathToSongDir)

    # Test one song each time
    for i, t_SongName in enumerate(t_AllFiles):

        print("Processing...", t_SongName)

        if t_SongName.endswith(".mp3"):

            t_PathToSingleSong = f'{a_PathToSongDir}/{t_SongName}'
            t_Patterns, t_Labels = generate_patterns_for_one_song(t_PathToSingleSong,
                                        a_Label, a_SizeOfWindow, a_NumOfOverlapSample)

            for j in range(t_Patterns.shape[2]):
                t_Patterns[:, :, j] = a_Scalers[j].transform(t_Patterns[:, :, j])

            # Reshape to 4D
            t_Patterns = t_Patterns[:,:,:,newaxis]

            # Sum results from each song
            t_DictSingleSong = classify_song(a_Model, t_Patterns, a_Label)
            t_AllResultsDict = Counter(t_AllResultsDict) + Counter(t_DictSingleSong)

            #Force display zero frequency object
            t_AllResultsDict.update({x:0 for x in t_DictSingleSong})

        print("Validating song No.", i+1, "/", len(t_AllFiles), "....Current results ", t_AllResultsDict)



'''
Evaluate model by using the extracted validation Mel-spectrogram
generated by generateTestset.py

(Recommand to use this method, if user is going to validate the model
 using the same songs repeatly)

NOTE that please use generateTestset.py to generate .pkl files.
The data structure of training set and validation set are different!
'''
def test_model_use_pkl(a_Model, a_Scalers, a_SongList, a_Label):

    # Init recorder of classification results
    t_AllResultsDict={}

    for i, t_SongDict in enumerate(a_SongList):

        # Get pattern and Reshape to 4D
        t_Patterns = t_SongDict["Patterns"]

        for j in range(t_Patterns.shape[2]):
            t_Patterns[:, :, j] = a_Scalers[j].transform(t_Patterns[:, :, j])

        t_Patterns = t_Patterns[:,:,:,newaxis]

        # Sum results from each song
        t_DictSingleSong = classify_song(a_Model, t_Patterns, a_Label)
        t_AllResultsDict = Counter(t_AllResultsDict) + Counter(t_DictSingleSong)

        #Force display zero frequency object
        t_AllResultsDict.update({x:0 for x in t_DictSingleSong})

        print("Validating song No.", i+1, "/", len(a_SongList), "....Current results ", t_AllResultsDict)
